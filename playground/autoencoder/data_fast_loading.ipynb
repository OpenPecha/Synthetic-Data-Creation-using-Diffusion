{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0850c6b7-70c0-4896-ac8d-3cc5544f69fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 16640/16640 [01:07<00:00, 244.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors shape: (32, 768)\n",
      "Images shape: (32, 64, 2048, 1)\n",
      "Samples from the dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 08:55:27.477445: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 - Vector: [-0.09002203 -0.19136767 -0.1210061   0.0845647   0.33303985] Image shape: (64, 2048, 1)\n",
      "Sample 2 - Vector: [-0.5607847   0.01361169 -0.246679    0.2227611   0.15535183] Image shape: (64, 2048, 1)\n",
      "Sample 3 - Vector: [-0.20265871  0.03736514  0.02197978  0.05226846 -0.09203821] Image shape: (64, 2048, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 08:55:27.722918: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths and parameters\n",
    "image_folder_path = '/Selected_LG'\n",
    "vector_model_name = 'openpecha/tibetan_RoBERTa_S_e6'\n",
    "dataset_name = 'ta4tsering/Lhasa_kanjur_transcription_datasets'\n",
    "image_height = 64\n",
    "image_width = 2048\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(vector_model_name)\n",
    "model = TFAutoModel.from_pretrained(vector_model_name)\n",
    "\n",
    "def load_transcription_vector(transcription):\n",
    "    inputs = tokenizer(transcription, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(inputs)\n",
    "    return tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy().squeeze()\n",
    "\n",
    "def load_image(filename):\n",
    "    img_path = os.path.join(image_folder_path, filename)\n",
    "    img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "    img = img.resize((image_width, image_height))\n",
    "    img = np.array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "def process_example(example):\n",
    "    transcription = example['label']\n",
    "    filename = example['filename']\n",
    "    if filename in local_filenames:\n",
    "        vector = load_transcription_vector(transcription)\n",
    "        image = load_image(filename)\n",
    "        return vector, image\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Get the list of local filenames\n",
    "local_filenames = set(os.listdir(image_folder_path))\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(dataset_name, split='test')\n",
    "\n",
    "# Process the dataset using a for-loop\n",
    "vectors = []\n",
    "images = []\n",
    "\n",
    "for example in tqdm(dataset):\n",
    "    result = process_example(example)\n",
    "    if result is not None:\n",
    "        vector, image = result\n",
    "        vectors.append(vector)\n",
    "        images.append(image)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "vectors = np.array(vectors, dtype=np.float32)\n",
    "images = np.array(images, dtype=np.float32)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((vectors, images)).batch(32).cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Display the dataset structure\n",
    "for vec, img in tf_dataset.take(1):\n",
    "    print(\"Vectors shape:\", vec.shape)\n",
    "    print(\"Images shape:\", img.shape)\n",
    "\n",
    "# Print a few samples from the dataset\n",
    "print(\"Samples from the dataset:\")\n",
    "for vec, img in tf_dataset.take(1):\n",
    "    for i in range(3):\n",
    "        print(f\"Sample {i+1} - Vector:\", vec[i].numpy()[:5], \"Image shape:\", img[i].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e819321-53f0-4339-8dfe-2f58849c585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at openpecha/tibetan_RoBERTa_S_e6 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 16640/16640 [00:05<00:00, 2880.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors shape: (32, 768)\n",
      "Images shape: (32, 64, 2048, 1)\n",
      "Samples from the dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 09:12:47.652246: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-07-20 09:12:47.851498: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 - Vector: [-0.09011503 -0.19129862 -0.12103254  0.08446781  0.3330148 ] Image shape: (64, 2048, 1)\n",
      "Sample 2 - Vector: [-0.56067747  0.01370564 -0.24657749  0.2228653   0.15539485] Image shape: (64, 2048, 1)\n",
      "Sample 3 - Vector: [-0.20247729  0.03741506  0.02215673  0.05223634 -0.09218432] Image shape: (64, 2048, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 09:12:47.855514: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths and parameters\n",
    "image_folder_path = '/Selected_LG'\n",
    "vector_model_name = 'openpecha/tibetan_RoBERTa_S_e6'\n",
    "dataset_name = 'ta4tsering/Lhasa_kanjur_transcription_datasets'\n",
    "image_height = 64\n",
    "image_width = 2048\n",
    "\n",
    "# Load the tokenizer and model (PyTorch)\n",
    "tokenizer = AutoTokenizer.from_pretrained(vector_model_name)\n",
    "model = AutoModel.from_pretrained(vector_model_name).to('cuda')\n",
    "\n",
    "def load_transcription_vector(transcription):\n",
    "    inputs = tokenizer(transcription, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    vector = torch.mean(outputs.last_hidden_state, dim=1).squeeze()\n",
    "    return vector.cpu().numpy()\n",
    "\n",
    "def load_image(filename):\n",
    "    img_path = os.path.join(image_folder_path, filename)\n",
    "    img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "    img = img.resize((image_width, image_height))\n",
    "    img = np.array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "def process_example(example):\n",
    "    transcription = example['label']\n",
    "    filename = example['filename']\n",
    "    if filename in local_filenames:\n",
    "        vector = load_transcription_vector(transcription)\n",
    "        image = load_image(filename)\n",
    "        return vector, image\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Get the list of local filenames\n",
    "local_filenames = set(os.listdir(image_folder_path))\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(dataset_name, split='test')\n",
    "\n",
    "# Process the dataset using a for-loop\n",
    "vectors = []\n",
    "images = []\n",
    "\n",
    "for example in tqdm(dataset):\n",
    "    result = process_example(example)\n",
    "    if result is not None:\n",
    "        vector, image = result\n",
    "        vectors.append(vector)\n",
    "        images.append(image)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "vectors = np.array(vectors, dtype=np.float32)\n",
    "images = np.array(images, dtype=np.float32)\n",
    "\n",
    "# Convert numpy arrays to TensorFlow tensors\n",
    "tf_vectors = tf.convert_to_tensor(vectors)\n",
    "tf_images = tf.convert_to_tensor(images)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((tf_vectors, tf_images)).batch(32).cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Display the dataset structure\n",
    "for vec, img in tf_dataset.take(1):\n",
    "    print(\"Vectors shape:\", vec.shape)\n",
    "    print(\"Images shape:\", img.shape)\n",
    "\n",
    "# Print a few samples from the dataset\n",
    "print(\"Samples from the dataset:\")\n",
    "for vec, img in tf_dataset.take(1):\n",
    "    for i in range(3):\n",
    "        print(f\"Sample {i+1} - Vector:\", vec[i].numpy()[:5], \"Image shape:\", img[i].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b38b391-ef25-4855-9f17-1b5abea68c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1000/1000 [01:08<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and processing took 68.26 seconds\n",
      "Vectors shape: (32, 768)\n",
      "Images shape: (32, 64, 2048, 1)\n",
      "Samples from the dataset:\n",
      "Sample 1 - Vector: [ 0.25963187 -0.25010753 -0.10972076 -0.03690102  0.16365188] Image shape: (64, 2048, 1)\n",
      "Sample 2 - Vector: [ 0.33421978 -0.2964837  -0.42488924 -0.04383376  0.4691976 ] Image shape: (64, 2048, 1)\n",
      "Sample 3 - Vector: [ 0.02504182 -0.29210714 -0.37100416 -0.244986    0.64311194] Image shape: (64, 2048, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 07:33:12.849346: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-07-20 07:33:13.032653: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths and parameters\n",
    "image_folder_path = '/Selected_LG'\n",
    "vector_model_name = 'openpecha/tibetan_RoBERTa_S_e6'\n",
    "dataset_name = 'ta4tsering/Lhasa_kanjur_transcription_datasets'\n",
    "image_height = 64\n",
    "image_width = 2048\n",
    "batch_size = 32\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(vector_model_name)\n",
    "model = TFAutoModel.from_pretrained(vector_model_name)\n",
    "\n",
    "def load_transcription_vector(transcription):\n",
    "    inputs = tokenizer(transcription, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(inputs)\n",
    "    return tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy().squeeze()\n",
    "\n",
    "def load_image(filename):\n",
    "    img_path = os.path.join(image_folder_path, filename)\n",
    "    img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "    img = img.resize((image_width, image_height))\n",
    "    img = np.array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "# Get the list of local filenames\n",
    "local_filenames = set(os.listdir(image_folder_path))\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(dataset_name, split='test')\n",
    "\n",
    "# Create a dictionary for quick lookup of Hugging Face filenames\n",
    "hf_filenames = {example['filename']: example['label'] for example in dataset}\n",
    "\n",
    "# Create lists to store the vectors and images\n",
    "vectors_list = []\n",
    "images_list = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for filename in tqdm(local_filenames):\n",
    "    if filename in hf_filenames:\n",
    "        transcription = hf_filenames[filename]\n",
    "        vector = load_transcription_vector(transcription)\n",
    "        image = load_image(filename)\n",
    "        vectors_list.append(vector)\n",
    "        images_list.append(image)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Data loading and processing took {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Convert lists to TensorFlow dataset\n",
    "vectors_array = np.array(vectors_list)\n",
    "images_array = np.array(images_list)\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices((vectors_array, images_array))\n",
    "tf_dataset = tf_dataset.batch(batch_size)\n",
    "tf_dataset = tf_dataset.cache()\n",
    "tf_dataset = tf_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Display the dataset structure\n",
    "for vectors, images in tf_dataset.take(1):\n",
    "    print(\"Vectors shape:\", vectors.shape)\n",
    "    print(\"Images shape:\", images.shape)\n",
    "\n",
    "# Print a few samples from the dataset\n",
    "print(\"Samples from the dataset:\")\n",
    "for vectors, images in tf_dataset.take(1):\n",
    "    for i in range(3):\n",
    "        print(f\"Sample {i+1} - Vector:\", vectors[i].numpy()[:5], \"Image shape:\", images[i].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13bf70-d0c7-42a3-9fca-5a112ab892d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Reshape, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the autoencoder model\n",
    "def build_autoencoder(input_shape, vector_shape):\n",
    "    # Encoder\n",
    "    text_input = Input(shape=vector_shape)\n",
    "    x = Dense(1024, activation='relu')(text_input)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    encoded = Dense(256, activation='relu')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = Dense(512, activation='relu')(encoded)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(input_shape[0] * input_shape[1], activation='sigmoid')(x)\n",
    "    decoded = Reshape(input_shape)(x)\n",
    "\n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(text_input, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Define the input shape and vector shape\n",
    "input_shape = (image_height, image_width, 1)\n",
    "vector_shape = (768,)  # Adjust based on the actual vector size from your text embeddings\n",
    "\n",
    "# Build the autoencoder model\n",
    "autoencoder = build_autoencoder(input_shape, vector_shape)\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(tf_dataset, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8857ccd4-2d88-4ce6-b94d-696a427f955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 type: <class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
      "Dataset 2 type: <class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
      "Dataset 1 element_spec: (TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))\n",
      "Dataset 2 element_spec: (TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))\n",
      "Difference in attribute '__bool__':\n",
      "Dataset1: <bound method DatasetV2.__bool__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.__bool__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '__debug_string__':\n",
      "Dataset1: <bound method DatasetV2.__debug_string__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.__debug_string__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '__delattr__':\n",
      "Dataset1: <method-wrapper '__delattr__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__delattr__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__dict__':\n",
      "Dataset1: {'_input_dataset': <CacheDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>, '_buffer_size': <tf.Tensor: shape=(), dtype=int64, numpy=-1>, '_name': None, '_variant_tensor_attr': <tf.Tensor: shape=(), dtype=variant, value=<PrefetchDatasetOp::Dataset>>, '_graph_attr': <tensorflow.python.framework.ops.Graph object at 0x7fed27d9b4c0>, '_options_attr': <tensorflow.python.data.ops.options.Options object at 0x7fed27dcd650>, '_self_setattr_tracking': True}\n",
      "Dataset2: {'_input_dataset': <CacheDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>, '_buffer_size': <tf.Tensor: shape=(), dtype=int64, numpy=-1>, '_name': None, '_variant_tensor_attr': <tf.Tensor: shape=(), dtype=variant, value=<PrefetchDatasetOp::Dataset>>, '_graph_attr': <tensorflow.python.framework.ops.Graph object at 0x7fed27d9b4c0>, '_options_attr': <tensorflow.python.data.ops.options.Options object at 0x7fed277c0510>, '_self_setattr_tracking': True}\n",
      "Difference in attribute '__dir__':\n",
      "Dataset1: <built-in method __dir__ of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <built-in method __dir__ of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__eq__':\n",
      "Dataset1: <method-wrapper '__eq__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__eq__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__format__':\n",
      "Dataset1: <built-in method __format__ of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <built-in method __format__ of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__ge__':\n",
      "Dataset1: <method-wrapper '__ge__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__ge__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__getattribute__':\n",
      "Dataset1: <method-wrapper '__getattribute__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__getattribute__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__getstate__':\n",
      "Dataset1: <built-in method __getstate__ of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <built-in method __getstate__ of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__gt__':\n",
      "Dataset1: <method-wrapper '__gt__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__gt__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__hash__':\n",
      "Dataset1: <method-wrapper '__hash__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__hash__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__init__':\n",
      "Dataset1: <bound method _PrefetchDataset.__init__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method _PrefetchDataset.__init__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '__iter__':\n",
      "Dataset1: <bound method DatasetV2.__iter__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.__iter__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '__le__':\n",
      "Dataset1: <method-wrapper '__le__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__le__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__len__':\n",
      "Dataset1: <bound method DatasetV2.__len__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.__len__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '__lt__':\n",
      "Dataset1: <method-wrapper '__lt__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__lt__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__ne__':\n",
      "Dataset1: <method-wrapper '__ne__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__ne__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__nonzero__':\n",
      "Dataset1: <bound method DatasetV2.__bool__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.__bool__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '__reduce__':\n",
      "Dataset1: <built-in method __reduce__ of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <built-in method __reduce__ of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__reduce_ex__':\n",
      "Dataset1: <built-in method __reduce_ex__ of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <built-in method __reduce_ex__ of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__repr__':\n",
      "Dataset1: <bound method DatasetV2.__repr__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.__repr__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '__setattr__':\n",
      "Dataset1: <method-wrapper '__setattr__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__setattr__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__sizeof__':\n",
      "Dataset1: <built-in method __sizeof__ of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <built-in method __sizeof__ of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__str__':\n",
      "Dataset1: <method-wrapper '__str__' of _PrefetchDataset object at 0x7fed27651dd0>\n",
      "Dataset2: <method-wrapper '__str__' of _PrefetchDataset object at 0x7fed28e6b890>\n",
      "Difference in attribute '__tf_tracing_type__':\n",
      "Dataset1: <bound method CompositeTensor.__tf_tracing_type__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method CompositeTensor.__tf_tracing_type__ of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_add_trackable_child':\n",
      "Dataset1: <bound method Trackable._add_trackable_child of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._add_trackable_child of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_add_variable_with_custom_getter':\n",
      "Dataset1: <bound method Trackable._add_variable_with_custom_getter of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._add_variable_with_custom_getter of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_apply_debug_options':\n",
      "Dataset1: <bound method DatasetV2._apply_debug_options of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2._apply_debug_options of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_as_serialized_graph':\n",
      "Dataset1: <bound method DatasetV2._as_serialized_graph of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2._as_serialized_graph of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_checkpoint_adapter':\n",
      "Dataset1: <bound method Trackable._checkpoint_adapter of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._checkpoint_adapter of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Error while comparing attribute _checkpoint_dependencies: '_PrefetchDataset' object has no attribute '_self_unconditional_checkpoint_dependencies'\n",
      "Difference in attribute '_consumers':\n",
      "Dataset1: <bound method CompositeTensor._consumers of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method CompositeTensor._consumers of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_convert_variables_to_tensors':\n",
      "Dataset1: <bound method CompositeTensor._convert_variables_to_tensors of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method CompositeTensor._convert_variables_to_tensors of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_copy_trackable_to_cpu':\n",
      "Dataset1: <bound method Trackable._copy_trackable_to_cpu of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._copy_trackable_to_cpu of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Error while comparing attribute _deferred_dependencies: '_PrefetchDataset' object has no attribute '_self_unconditional_deferred_dependencies'\n",
      "Difference in attribute '_deserialization_dependencies':\n",
      "Dataset1: <bound method Trackable._deserialization_dependencies of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._deserialization_dependencies of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_export_to_saved_model_graph':\n",
      "Dataset1: <bound method Trackable._export_to_saved_model_graph of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._export_to_saved_model_graph of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_functions':\n",
      "Dataset1: <bound method DatasetV2._functions of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2._functions of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_gather_saveables_for_checkpoint':\n",
      "Dataset1: <bound method Trackable._gather_saveables_for_checkpoint of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._gather_saveables_for_checkpoint of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_handle_deferred_dependencies':\n",
      "Dataset1: <bound method Trackable._handle_deferred_dependencies of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._handle_deferred_dependencies of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_input_dataset':\n",
      "Dataset1: <CacheDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>\n",
      "Dataset2: <CacheDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>\n",
      "Difference in attribute '_inputs':\n",
      "Dataset1: <bound method UnaryDataset._inputs of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method UnaryDataset._inputs of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_lookup_dependency':\n",
      "Dataset1: <bound method Trackable._lookup_dependency of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._lookup_dependency of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_maybe_initialize_trackable':\n",
      "Dataset1: <bound method Trackable._maybe_initialize_trackable of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._maybe_initialize_trackable of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_maybe_track_assets':\n",
      "Dataset1: <bound method DatasetV2._maybe_track_assets of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2._maybe_track_assets of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_name_based_attribute_restore':\n",
      "Dataset1: <bound method Trackable._name_based_attribute_restore of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._name_based_attribute_restore of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Error while comparing attribute _name_based_restores: '_PrefetchDataset' object has no attribute '_self_name_based_restores'\n",
      "Difference in attribute '_no_dependency':\n",
      "Dataset1: <bound method Trackable._no_dependency of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._no_dependency of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_options':\n",
      "Dataset1: <bound method DatasetV2._options of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2._options of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_preload_simple_restoration':\n",
      "Dataset1: <bound method Trackable._preload_simple_restoration of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._preload_simple_restoration of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_restore_from_tensors':\n",
      "Dataset1: <bound method Trackable._restore_from_tensors of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._restore_from_tensors of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_serialize_to_proto':\n",
      "Dataset1: <bound method Trackable._serialize_to_proto of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._serialize_to_proto of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_serialize_to_tensors':\n",
      "Dataset1: <bound method Trackable._serialize_to_tensors of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._serialize_to_tensors of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_shape_invariant_to_type_spec':\n",
      "Dataset1: <bound method CompositeTensor._shape_invariant_to_type_spec of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method CompositeTensor._shape_invariant_to_type_spec of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_trace_variant_creation':\n",
      "Dataset1: <bound method DatasetV2._trace_variant_creation of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2._trace_variant_creation of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_track_trackable':\n",
      "Dataset1: <bound method Trackable._track_trackable of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method Trackable._track_trackable of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute '_trackable_children':\n",
      "Dataset1: <bound method DatasetV2._trackable_children of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2._trackable_children of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Error while comparing attribute _unconditional_checkpoint_dependencies: '_PrefetchDataset' object has no attribute '_self_unconditional_checkpoint_dependencies'\n",
      "Error while comparing attribute _unconditional_dependency_names: '_PrefetchDataset' object has no attribute '_self_unconditional_dependency_names'\n",
      "Error while comparing attribute _update_uid: '_PrefetchDataset' object has no attribute '_self_update_uid'\n",
      "Difference in attribute '_variant_tensor': unable to directly compare values\n",
      "Difference in attribute '_variant_tensor_attr': unable to directly compare values\n",
      "Difference in attribute 'apply':\n",
      "Dataset1: <bound method DatasetV2.apply of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.apply of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'as_numpy_iterator':\n",
      "Dataset1: <bound method DatasetV2.as_numpy_iterator of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.as_numpy_iterator of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'batch':\n",
      "Dataset1: <bound method DatasetV2.batch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.batch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'bucket_by_sequence_length':\n",
      "Dataset1: <bound method DatasetV2.bucket_by_sequence_length of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.bucket_by_sequence_length of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'cache':\n",
      "Dataset1: <bound method DatasetV2.cache of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.cache of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'cardinality':\n",
      "Dataset1: <bound method DatasetV2.cardinality of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.cardinality of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'concatenate':\n",
      "Dataset1: <bound method DatasetV2.concatenate of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.concatenate of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'enumerate':\n",
      "Dataset1: <bound method DatasetV2.enumerate of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.enumerate of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'filter':\n",
      "Dataset1: <bound method DatasetV2.filter of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.filter of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'fingerprint':\n",
      "Dataset1: <bound method DatasetV2.fingerprint of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.fingerprint of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'flat_map':\n",
      "Dataset1: <bound method DatasetV2.flat_map of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.flat_map of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'get_single_element':\n",
      "Dataset1: <bound method DatasetV2.get_single_element of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.get_single_element of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'group_by_window':\n",
      "Dataset1: <bound method DatasetV2.group_by_window of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.group_by_window of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'ignore_errors':\n",
      "Dataset1: <bound method DatasetV2.ignore_errors of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.ignore_errors of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'interleave':\n",
      "Dataset1: <bound method DatasetV2.interleave of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.interleave of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'map':\n",
      "Dataset1: <bound method DatasetV2.map of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.map of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'options':\n",
      "Dataset1: <bound method DatasetV2.options of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.options of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'padded_batch':\n",
      "Dataset1: <bound method DatasetV2.padded_batch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.padded_batch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'prefetch':\n",
      "Dataset1: <bound method DatasetV2.prefetch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.prefetch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'ragged_batch':\n",
      "Dataset1: <bound method DatasetV2.ragged_batch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.ragged_batch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'rebatch':\n",
      "Dataset1: <bound method DatasetV2.rebatch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.rebatch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'reduce':\n",
      "Dataset1: <bound method DatasetV2.reduce of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.reduce of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'rejection_resample':\n",
      "Dataset1: <bound method DatasetV2.rejection_resample of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.rejection_resample of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'repeat':\n",
      "Dataset1: <bound method DatasetV2.repeat of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.repeat of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'save':\n",
      "Dataset1: <bound method DatasetV2.save of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.save of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'scan':\n",
      "Dataset1: <bound method DatasetV2.scan of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.scan of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'shard':\n",
      "Dataset1: <bound method DatasetV2.shard of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.shard of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'shuffle':\n",
      "Dataset1: <bound method DatasetV2.shuffle of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.shuffle of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'skip':\n",
      "Dataset1: <bound method DatasetV2.skip of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.skip of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'snapshot':\n",
      "Dataset1: <bound method DatasetV2.snapshot of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.snapshot of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'sparse_batch':\n",
      "Dataset1: <bound method DatasetV2.sparse_batch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.sparse_batch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'take':\n",
      "Dataset1: <bound method DatasetV2.take of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.take of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'take_while':\n",
      "Dataset1: <bound method DatasetV2.take_while of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.take_while of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'unbatch':\n",
      "Dataset1: <bound method DatasetV2.unbatch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.unbatch of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'unique':\n",
      "Dataset1: <bound method DatasetV2.unique of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.unique of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'window':\n",
      "Dataset1: <bound method DatasetV2.window of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.window of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Difference in attribute 'with_options':\n",
      "Dataset1: <bound method DatasetV2.with_options of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n",
      "Dataset2: <bound method DatasetV2.with_options of <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 2048, 1), dtype=tf.float32, name=None))>>\n"
     ]
    }
   ],
   "source": [
    "def compare_datasets(ds1, ds2):\n",
    "    # Compare the types and element specs\n",
    "    print(\"Dataset 1 type:\", type(ds1))\n",
    "    print(\"Dataset 2 type:\", type(ds2))\n",
    "    print(\"Dataset 1 element_spec:\", ds1.element_spec)\n",
    "    print(\"Dataset 2 element_spec:\", ds2.element_spec)\n",
    "    \n",
    "    # Compare attributes\n",
    "    ds1_attributes = dir(ds1)\n",
    "    ds2_attributes = dir(ds2)\n",
    "    \n",
    "    for attr in ds1_attributes:\n",
    "        if attr in ds2_attributes:\n",
    "            try:\n",
    "                val1 = getattr(ds1, attr)\n",
    "                val2 = getattr(ds2, attr)\n",
    "                try:\n",
    "                    if val1 != val2:\n",
    "                        print(f\"Difference in attribute '{attr}':\")\n",
    "                        print(f\"Dataset1: {val1}\")\n",
    "                        print(f\"Dataset2: {val2}\")\n",
    "                except:\n",
    "                    print(f\"Difference in attribute '{attr}': unable to directly compare values\")\n",
    "            except AttributeError as e:\n",
    "                print(f\"Error while comparing attribute {attr}: {e}\")\n",
    "\n",
    "# Compare the datasets\n",
    "compare_datasets(tf_dataset_for_loop, tf_dataset_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb456ac-9276-4801-adf9-9225c6491a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
