{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01bd7617-7ca7-4cd9-868a-123c7cb4e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 21:40:52.168811: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-23 21:40:52.179825: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 21:40:52.192299: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 21:40:52.196061: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 21:40:52.205968: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at openpecha/tibetan_RoBERTa_S_e6 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "from diffusers import UNet2DModel, DDPMScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add the monlam_ocr module to the Python path\n",
    "src_path = '/monlam_ocr-main/src'  # Adjust this path if needed\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Import the monlam_ocr module\n",
    "from monlam_ocr.config import get_models_path\n",
    "from monlam_ocr.line_detection import LineDetection\n",
    "from monlam_ocr.ocr import OCRInference\n",
    "from monlam_ocr.predict import run_ocr\n",
    "\n",
    "# Set the GitHub token as an environment variable\n",
    "os.environ['GITHUB_TOKEN'] = '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'\n",
    "\n",
    "# Initialize the OCR model\n",
    "line_model_config_path, ocr_model_config_path = get_models_path()\n",
    "line_inference = LineDetection(line_model_config_path)\n",
    "ocr_inference = OCRInference(ocr_model_config_path)\n",
    "\n",
    "# Load the train split from the Hugging Face dataset\n",
    "dataset = load_dataset('ta4tsering/Lhasa_kanjur_transcription_datasets', split='train')\n",
    "\n",
    "# Extract filenames and transcriptions\n",
    "filenames = dataset['filename']\n",
    "transcriptions = dataset['label']\n",
    "\n",
    "# Load pre-trained model and tokenizer for text embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained('openpecha/tibetan_RoBERTa_S_e6')\n",
    "model_roberta = AutoModel.from_pretrained('openpecha/tibetan_RoBERTa_S_e6').to('cuda')\n",
    "\n",
    "# Function to batch convert texts to vectors using GPU\n",
    "def texts_to_vectors(texts, batch_size=32):\n",
    "    vectors = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True).to('cuda')\n",
    "        with torch.no_grad():\n",
    "            outputs = model_roberta(**inputs)\n",
    "        batch_vectors = outputs.last_hidden_state.mean(dim=1).detach().cpu().numpy()\n",
    "        vectors.extend(batch_vectors)\n",
    "    return vectors\n",
    "\n",
    "# Pre-compute text embeddings in batches using GPU\n",
    "text_vectors = texts_to_vectors(transcriptions)\n",
    "\n",
    "# Custom dataset class with pre-computed text embeddings\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, filenames, text_vectors, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.filenames = filenames\n",
    "        self.text_vectors = text_vectors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.filenames[idx])\n",
    "        image = Image.open(img_name).convert(\"L\")  # Convert to grayscale\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        text_vector = self.text_vectors[idx]\n",
    "        return image, text_vector\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 2048)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize for grayscale images\n",
    "])\n",
    "\n",
    "# Define the dataset and dataloader\n",
    "image_dir = '/local_dir/Train_Images'  # Adjust to your local directory\n",
    "dataset = CustomDataset(image_dir=image_dir, filenames=filenames, text_vectors=text_vectors, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "183ac13d-e723-4d33-82bb-189d304607ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Function to preprocess and check image dimensions\n",
    "def preprocess_image_for_ocr(image_tensor):\n",
    "    image_np = image_tensor.squeeze().detach().cpu().numpy() * 255.0  # Denormalize\n",
    "    image_np = image_np.astype(np.uint8)  # Ensure it's in the correct type\n",
    "    # Ensure the image is 2D\n",
    "    if image_np.ndim == 3:\n",
    "        image_np = image_np[0]\n",
    "    return image_np\n",
    "\n",
    "# Define the OCR function\n",
    "def run_ocr(image_path, line_inference, ocr_inference):\n",
    "    try:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        line_images = [image]  # Use the whole image as a single line image\n",
    "        predicted_text, _ = ocr_inference.run(line_images)\n",
    "    except cv2.error as e:\n",
    "        raise Exception(f\"OpenCV error in processing {image_path}: {e}\")\n",
    "    except IndexError as e:\n",
    "        raise Exception(f\"Dimension error in processing {image_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Unexpected error in OCR processing: {e}\")\n",
    "    return predicted_text[0] if isinstance(predicted_text, list) else predicted_text\n",
    "\n",
    "class SimpleConditionalDDPMWithOCR(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(SimpleConditionalDDPMWithOCR, self).__init__()\n",
    "        self.model = UNet2DModel(\n",
    "            sample_size=(64, 2048),\n",
    "            in_channels=2,  # Update to accept 2 channels (image + text)\n",
    "            out_channels=1,\n",
    "            layers_per_block=2,\n",
    "            block_out_channels=(64, 128, 256, 512),\n",
    "            down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\"),\n",
    "            up_block_types=(\"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\")\n",
    "        )\n",
    "        self.text_embedding = nn.Linear(768, 64 * 2048)  # Adjust dimensions as needed\n",
    "        self.scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, t, text_vector):\n",
    "        # Convert text_vector to match image dimensions\n",
    "        text_embedding = self.text_embedding(text_vector).view(-1, 1, 64, 2048)\n",
    "        # Concatenate image and text embeddings\n",
    "        x = torch.cat((x, text_embedding), dim=1)\n",
    "        return self.model(x, t).sample\n",
    "\n",
    "    def custom_loss(self, predicted_noise, noise, generated_image, condition_vector):\n",
    "        # Compute the MSE loss\n",
    "        mse_loss = self.criterion(predicted_noise, noise)\n",
    "        # Preprocess the generated image for OCR\n",
    "        try:\n",
    "            generated_image_np = preprocess_image_for_ocr(generated_image)\n",
    "        except Exception as e:\n",
    "            print(f\"Image preprocessing error: {e}\")\n",
    "            return mse_loss  # Return MSE loss if preprocessing fails\n",
    "        # Save the preprocessed image temporarily\n",
    "        temp_image_path = \"temp_image.png\"\n",
    "        cv2.imwrite(temp_image_path, generated_image_np)\n",
    "        # Use OCR to extract text from the generated image\n",
    "        try:\n",
    "            predicted_text = run_ocr(temp_image_path, line_inference, ocr_inference)\n",
    "        except Exception as e:\n",
    "            print(f\"OCR processing error: {e}\")\n",
    "            return mse_loss  # Return MSE loss if OCR fails\n",
    "        os.remove(temp_image_path)  # Clean up the temporary image\n",
    "        # Ensure predicted_text is a string and wrap it in a list\n",
    "        if isinstance(predicted_text, list):\n",
    "            predicted_text = predicted_text[0]\n",
    "        # Get the text vector of the OCR result\n",
    "        predicted_vector = texts_to_vectors([predicted_text])[0]\n",
    "        # Compute the loss between the condition vector and the predicted vector\n",
    "        text_loss = nn.MSELoss()(torch.tensor(predicted_vector).to(self.device), condition_vector)\n",
    "        # Combine the losses\n",
    "        combined_loss = mse_loss + 1.0 * text_loss  # Adjust the weight of the OCR loss as needed\n",
    "        return combined_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, text_vectors = batch\n",
    "        images = images.to(self.device)\n",
    "        text_vectors = torch.tensor(text_vectors).to(self.device)\n",
    "        t = torch.randint(0, self.scheduler.config.num_train_timesteps, (images.size(0),), device=self.device).long()\n",
    "        noise = torch.randn_like(images).to(self.device)\n",
    "        noisy_images = self.scheduler.add_noise(original_samples=images, noise=noise, timesteps=t)\n",
    "        predicted_noise = self(noisy_images, t, text_vectors)\n",
    "        generated_image = self.scheduler.step(predicted_noise[0].unsqueeze(0), t[0], noisy_images[0].unsqueeze(0)).prev_sample\n",
    "        loss = self.custom_loss(predicted_noise, noise, generated_image, text_vectors[0])\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "# Initialize the model with OCR-based loss\n",
    "model_with_ocr = SimpleConditionalDDPMWithOCR()\n",
    "\n",
    "# Define the trainer\n",
    "trainer_with_ocr = pl.Trainer(\n",
    "    accumulate_grad_batches=4,  # Gradient accumulation\n",
    "    precision=16,  # Mixed precision\n",
    "    max_epochs=50,  # Continue training for another 50 epochs with OCR-based loss\n",
    "    accelerator='gpu',\n",
    "    devices=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03409a38-d5d9-4096-affd-1673c188b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /lightning_logs/version_18/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type        | Params | Mode\n",
      "------------------------------------------------------\n",
      "0 | model          | UNet2DModel | 56.6 M | eval\n",
      "1 | text_embedding | Linear      | 100 M  | eval\n",
      "2 | criterion      | MSELoss     | 0      | eval\n",
      "------------------------------------------------------\n",
      "157 M     Trainable params\n",
      "0         Non-trainable params\n",
      "157 M     Total params\n",
      "629.469   Total estimated model params size (MB)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694c580e3e5842a19cc066dee72843a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_7123/2290144861.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_vectors = torch.tensor(text_vectors).to(self.device)\n"
     ]
    }
   ],
   "source": [
    "# Continue training the model with OCR-based loss\n",
    "trainer_with_ocr.fit(model_with_ocr, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48225f-9f8e-4fbf-bfe2-a7623931544b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 5/1000 [00:00<00:22, 44.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 10/1000 [00:00<00:22, 43.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 15/1000 [00:00<00:22, 43.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 20/1000 [00:00<00:22, 42.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▎         | 25/1000 [00:00<00:22, 42.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 30/1000 [00:00<00:22, 42.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 35/1000 [00:00<00:22, 42.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 40/1000 [00:00<00:22, 42.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 45/1000 [00:01<00:22, 42.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 50/1000 [00:01<00:22, 42.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 55/1000 [00:01<00:22, 42.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 60/1000 [00:01<00:21, 42.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 65/1000 [00:01<00:21, 42.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 70/1000 [00:01<00:21, 42.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 75/1000 [00:01<00:21, 42.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 80/1000 [00:01<00:21, 42.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 85/1000 [00:01<00:21, 42.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 90/1000 [00:02<00:21, 42.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 95/1000 [00:02<00:21, 42.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 100/1000 [00:02<00:20, 42.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 105/1000 [00:02<00:20, 42.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 110/1000 [00:02<00:20, 43.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 115/1000 [00:02<00:20, 43.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:02<00:20, 43.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▎        | 125/1000 [00:02<00:20, 42.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 130/1000 [00:03<00:20, 43.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 135/1000 [00:03<00:20, 43.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 140/1000 [00:03<00:19, 43.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 145/1000 [00:03<00:19, 43.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 150/1000 [00:03<00:19, 42.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 155/1000 [00:03<00:19, 42.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 160/1000 [00:03<00:19, 43.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 165/1000 [00:03<00:19, 43.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 170/1000 [00:03<00:19, 43.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 175/1000 [00:04<00:18, 43.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 180/1000 [00:04<00:18, 44.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 185/1000 [00:04<00:18, 44.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 190/1000 [00:04<00:18, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 195/1000 [00:04<00:18, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 200/1000 [00:04<00:17, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 205/1000 [00:04<00:17, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 210/1000 [00:04<00:17, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 215/1000 [00:04<00:17, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 220/1000 [00:05<00:17, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▎       | 225/1000 [00:05<00:17, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 230/1000 [00:05<00:17, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 235/1000 [00:05<00:16, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 240/1000 [00:05<00:16, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 245/1000 [00:05<00:16, 45.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 250/1000 [00:05<00:16, 45.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 255/1000 [00:05<00:16, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 260/1000 [00:05<00:16, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 265/1000 [00:06<00:16, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 270/1000 [00:06<00:16, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 275/1000 [00:06<00:16, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 280/1000 [00:06<00:15, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 285/1000 [00:06<00:15, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 290/1000 [00:06<00:15, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 295/1000 [00:06<00:15, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 300/1000 [00:06<00:15, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 305/1000 [00:06<00:15, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 310/1000 [00:07<00:15, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 315/1000 [00:07<00:15, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 320/1000 [00:07<00:15, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▎      | 325/1000 [00:07<00:14, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 330/1000 [00:07<00:14, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 335/1000 [00:07<00:14, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 340/1000 [00:07<00:14, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 345/1000 [00:07<00:14, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 350/1000 [00:07<00:14, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 355/1000 [00:08<00:14, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:08<00:14, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 365/1000 [00:08<00:14, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 370/1000 [00:08<00:13, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 375/1000 [00:08<00:13, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 380/1000 [00:08<00:13, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 385/1000 [00:08<00:13, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 390/1000 [00:08<00:13, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 395/1000 [00:08<00:13, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 400/1000 [00:09<00:13, 45.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 405/1000 [00:09<00:13, 45.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 410/1000 [00:09<00:13, 45.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 415/1000 [00:09<00:12, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 420/1000 [00:09<00:12, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▎     | 425/1000 [00:09<00:12, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 430/1000 [00:09<00:12, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 435/1000 [00:09<00:12, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 440/1000 [00:09<00:12, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 445/1000 [00:10<00:12, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 450/1000 [00:10<00:12, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 455/1000 [00:10<00:12, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 460/1000 [00:10<00:11, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 465/1000 [00:10<00:11, 45.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 470/1000 [00:10<00:11, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 475/1000 [00:10<00:11, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 480/1000 [00:10<00:11, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 485/1000 [00:10<00:11, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 490/1000 [00:11<00:11, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 495/1000 [00:11<00:11, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 500/1000 [00:11<00:11, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 505/1000 [00:11<00:10, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 510/1000 [00:11<00:10, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 515/1000 [00:11<00:10, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 520/1000 [00:11<00:10, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▎    | 525/1000 [00:11<00:10, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 530/1000 [00:11<00:10, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 535/1000 [00:12<00:10, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 540/1000 [00:12<00:10, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 545/1000 [00:12<00:10, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 550/1000 [00:12<00:09, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 555/1000 [00:12<00:09, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 560/1000 [00:12<00:09, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 565/1000 [00:12<00:09, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 570/1000 [00:12<00:09, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▊    | 575/1000 [00:12<00:09, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 580/1000 [00:13<00:09, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 585/1000 [00:13<00:09, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 590/1000 [00:13<00:09, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 595/1000 [00:13<00:08, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 600/1000 [00:13<00:08, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 605/1000 [00:13<00:08, 45.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 610/1000 [00:13<00:08, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 615/1000 [00:13<00:08, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 620/1000 [00:13<00:08, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 625/1000 [00:14<00:08, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 630/1000 [00:14<00:08, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 635/1000 [00:14<00:08, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 640/1000 [00:14<00:07, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 645/1000 [00:14<00:07, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 650/1000 [00:14<00:07, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 655/1000 [00:14<00:07, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 660/1000 [00:14<00:07, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 665/1000 [00:14<00:07, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 670/1000 [00:15<00:07, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 675/1000 [00:15<00:07, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 680/1000 [00:15<00:07, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 685/1000 [00:15<00:06, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 690/1000 [00:15<00:06, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 695/1000 [00:15<00:06, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 700/1000 [00:15<00:06, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 705/1000 [00:15<00:06, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 710/1000 [00:15<00:06, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 715/1000 [00:16<00:06, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 720/1000 [00:16<00:06, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▎  | 725/1000 [00:16<00:06, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 730/1000 [00:16<00:05, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 735/1000 [00:16<00:05, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 740/1000 [00:16<00:05, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 745/1000 [00:16<00:05, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 750/1000 [00:16<00:05, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 755/1000 [00:16<00:05, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 760/1000 [00:17<00:05, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 765/1000 [00:17<00:05, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 770/1000 [00:17<00:05, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 775/1000 [00:17<00:05, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 780/1000 [00:17<00:04, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 785/1000 [00:17<00:04, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 790/1000 [00:17<00:04, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 795/1000 [00:17<00:04, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 800/1000 [00:17<00:04, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 805/1000 [00:18<00:04, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 810/1000 [00:18<00:04, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 815/1000 [00:18<00:04, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 820/1000 [00:18<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▎ | 825/1000 [00:18<00:03, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 830/1000 [00:18<00:03, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 835/1000 [00:18<00:03, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:18<00:03, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 845/1000 [00:18<00:03, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 850/1000 [00:19<00:03, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 855/1000 [00:19<00:03, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 860/1000 [00:19<00:03, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 865/1000 [00:19<00:03, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 870/1000 [00:19<00:02, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 875/1000 [00:19<00:02, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 880/1000 [00:19<00:02, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 885/1000 [00:19<00:02, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 890/1000 [00:19<00:02, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 895/1000 [00:20<00:02, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 900/1000 [00:20<00:02, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 905/1000 [00:20<00:02, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 910/1000 [00:20<00:02, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 915/1000 [00:20<00:01, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 920/1000 [00:20<00:01, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▎| 925/1000 [00:20<00:01, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 930/1000 [00:20<00:01, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 935/1000 [00:20<00:01, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 940/1000 [00:21<00:01, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 945/1000 [00:21<00:01, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 950/1000 [00:21<00:01, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 955/1000 [00:21<00:00, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 960/1000 [00:21<00:00, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 965/1000 [00:21<00:00, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 970/1000 [00:21<00:00, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 975/1000 [00:21<00:00, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 980/1000 [00:21<00:00, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 985/1000 [00:22<00:00, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 990/1000 [00:22<00:00, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 995/1000 [00:22<00:00, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1000/1000 [00:22<00:00, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                   \u001b[A\u001b[A\n",
      " 50%|█████     | 1/2 [00:22<00:22, 22.41s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 5/1000 [00:00<00:21, 46.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 10/1000 [00:00<00:21, 45.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 15/1000 [00:00<00:21, 45.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 20/1000 [00:00<00:21, 45.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▎         | 25/1000 [00:00<00:21, 45.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 30/1000 [00:00<00:21, 45.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 35/1000 [00:00<00:21, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 40/1000 [00:00<00:21, 45.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 45/1000 [00:00<00:21, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 50/1000 [00:01<00:21, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 55/1000 [00:01<00:20, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 60/1000 [00:01<00:20, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 65/1000 [00:01<00:20, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 70/1000 [00:01<00:20, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 75/1000 [00:01<00:20, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 80/1000 [00:01<00:20, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 85/1000 [00:01<00:20, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 90/1000 [00:01<00:20, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 95/1000 [00:02<00:20, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 100/1000 [00:02<00:19, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 105/1000 [00:02<00:19, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 110/1000 [00:02<00:19, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 115/1000 [00:02<00:19, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:02<00:19, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▎        | 125/1000 [00:02<00:19, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 130/1000 [00:02<00:19, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 135/1000 [00:02<00:19, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 140/1000 [00:03<00:19, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 145/1000 [00:03<00:19, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 150/1000 [00:03<00:18, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 155/1000 [00:03<00:18, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 160/1000 [00:03<00:18, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 165/1000 [00:03<00:18, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 170/1000 [00:03<00:18, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 175/1000 [00:03<00:18, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 180/1000 [00:03<00:18, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 185/1000 [00:04<00:18, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 190/1000 [00:04<00:18, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 195/1000 [00:04<00:17, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 200/1000 [00:04<00:17, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 205/1000 [00:04<00:17, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 210/1000 [00:04<00:17, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 215/1000 [00:04<00:17, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 220/1000 [00:04<00:17, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▎       | 225/1000 [00:05<00:17, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 230/1000 [00:05<00:17, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 235/1000 [00:05<00:17, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 240/1000 [00:05<00:16, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 245/1000 [00:05<00:16, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 250/1000 [00:05<00:16, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 255/1000 [00:05<00:16, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 260/1000 [00:05<00:16, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 265/1000 [00:05<00:16, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 270/1000 [00:06<00:16, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 275/1000 [00:06<00:16, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 280/1000 [00:06<00:16, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 285/1000 [00:06<00:15, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 290/1000 [00:06<00:15, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 295/1000 [00:06<00:15, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 300/1000 [00:06<00:15, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 305/1000 [00:06<00:15, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 310/1000 [00:06<00:15, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 315/1000 [00:07<00:15, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 320/1000 [00:07<00:15, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▎      | 325/1000 [00:07<00:15, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 330/1000 [00:07<00:14, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 335/1000 [00:07<00:14, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 340/1000 [00:07<00:14, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 345/1000 [00:07<00:14, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 350/1000 [00:07<00:14, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 355/1000 [00:07<00:14, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:08<00:14, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 365/1000 [00:08<00:14, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 370/1000 [00:08<00:14, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 375/1000 [00:08<00:13, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 380/1000 [00:08<00:13, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 385/1000 [00:08<00:13, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 390/1000 [00:08<00:13, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 395/1000 [00:08<00:13, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 400/1000 [00:08<00:13, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 405/1000 [00:09<00:13, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 410/1000 [00:09<00:13, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 415/1000 [00:09<00:13, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 420/1000 [00:09<00:12, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▎     | 425/1000 [00:09<00:12, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 430/1000 [00:09<00:12, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 435/1000 [00:09<00:12, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 440/1000 [00:09<00:12, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 445/1000 [00:09<00:12, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 450/1000 [00:10<00:12, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 455/1000 [00:10<00:12, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 460/1000 [00:10<00:12, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 465/1000 [00:10<00:11, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 470/1000 [00:10<00:11, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 475/1000 [00:10<00:11, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 480/1000 [00:10<00:11, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 485/1000 [00:10<00:11, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 490/1000 [00:10<00:11, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 495/1000 [00:11<00:11, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 500/1000 [00:11<00:11, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 505/1000 [00:11<00:11, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 510/1000 [00:11<00:10, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 515/1000 [00:11<00:10, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 520/1000 [00:11<00:10, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▎    | 525/1000 [00:11<00:10, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 530/1000 [00:11<00:10, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 535/1000 [00:11<00:10, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 540/1000 [00:12<00:10, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 545/1000 [00:12<00:10, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 550/1000 [00:12<00:10, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 555/1000 [00:12<00:09, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 560/1000 [00:12<00:09, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 565/1000 [00:12<00:09, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 570/1000 [00:12<00:09, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▊    | 575/1000 [00:12<00:09, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 580/1000 [00:12<00:09, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 585/1000 [00:13<00:09, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 590/1000 [00:13<00:09, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 595/1000 [00:13<00:09, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 600/1000 [00:13<00:08, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 605/1000 [00:13<00:08, 45.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 610/1000 [00:13<00:08, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 615/1000 [00:13<00:08, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 620/1000 [00:13<00:08, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 625/1000 [00:13<00:08, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 630/1000 [00:14<00:08, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 635/1000 [00:14<00:08, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 640/1000 [00:14<00:08, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 645/1000 [00:14<00:07, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 650/1000 [00:14<00:07, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 655/1000 [00:14<00:07, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 660/1000 [00:14<00:07, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 665/1000 [00:14<00:07, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 670/1000 [00:14<00:07, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 675/1000 [00:15<00:07, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 680/1000 [00:15<00:07, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 685/1000 [00:15<00:07, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 690/1000 [00:15<00:06, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 695/1000 [00:15<00:06, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 700/1000 [00:15<00:06, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 705/1000 [00:15<00:06, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 710/1000 [00:15<00:06, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 715/1000 [00:15<00:06, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 720/1000 [00:16<00:06, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▎  | 725/1000 [00:16<00:06, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 730/1000 [00:16<00:06, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 735/1000 [00:16<00:05, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 740/1000 [00:16<00:05, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 745/1000 [00:16<00:05, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 750/1000 [00:16<00:05, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 755/1000 [00:16<00:05, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 760/1000 [00:16<00:05, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 765/1000 [00:17<00:05, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 770/1000 [00:17<00:05, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 775/1000 [00:17<00:05, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 780/1000 [00:17<00:04, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 785/1000 [00:17<00:04, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 790/1000 [00:17<00:04, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 795/1000 [00:17<00:04, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 800/1000 [00:17<00:04, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 805/1000 [00:17<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 810/1000 [00:18<00:04, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 815/1000 [00:18<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 820/1000 [00:18<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▎ | 825/1000 [00:18<00:03, 44.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 830/1000 [00:18<00:03, 44.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 835/1000 [00:18<00:03, 44.75it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Function to generate conditional images from noise using a random text vector from training data\n",
    "def generate_conditional_images(model, scheduler, dataset, num_images=8, device='cuda'):\n",
    "    model.to(device)  # Ensure model is on the correct device\n",
    "    model.eval()\n",
    "    fig, axs = plt.subplots(2 * num_images, 1, figsize=(20, 5))\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(num_images)):\n",
    "            # Select a random image and text vector pair from the dataset\n",
    "            random_idx = random.randint(0, len(dataset) - 1)\n",
    "            image, random_text_vector = dataset[random_idx]\n",
    "            random_text_vector = torch.tensor(random_text_vector).to(device)\n",
    "            noise = torch.randn((1, 1, 64, 2048)).to(device)\n",
    "            for t in tqdm(range(scheduler.config.num_train_timesteps - 1, -1, -1), leave=False):\n",
    "                t_tensor = torch.tensor([t], device=device).long()\n",
    "                predicted_noise = model(noise, t_tensor, random_text_vector)\n",
    "                noise = scheduler.step(model_output=predicted_noise, timestep=t_tensor, sample=noise).prev_sample\n",
    "\n",
    "            # Display the generated image\n",
    "            axs[2 * i].imshow(noise.squeeze().cpu().numpy(), cmap='gray')\n",
    "            axs[2 * i].set_title(\"Generated Image\")\n",
    "            axs[2 * i].axis('off')\n",
    "\n",
    "            # Display the ground truth image\n",
    "            axs[2 * i + 1].imshow(image.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
    "            axs[2 * i + 1].set_title(\"Ground Truth Image\")\n",
    "            axs[2 * i + 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and display conditional images using random text vectors from the training data\n",
    "generate_conditional_images(model_with_ocr, model_with_ocr.scheduler, dataset, num_images=2, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049b49d-4c92-42b3-b44d-6cfa7d18cded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
